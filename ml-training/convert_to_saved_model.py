#!/usr/bin/env python3

"""
Convert H5 model to SavedModel format, then to TensorFlow.js
"""

import tensorflow as tf
from tensorflow import keras
import os
from pathlib import Path

def convert_h5_to_saved_model():
    """Convert H5 model to SavedModel format"""
    print("ğŸ”„ Converting H5 to SavedModel format...")
    print("=" * 60)
    
    h5_path = "models/ginger_disease_model.h5"
    saved_model_path = "exports/saved_model"
    
    if not os.path.exists(h5_path):
        print(f"âŒ Model not found: {h5_path}")
        return False
    
    try:
        # Load H5 model
        print(f"ğŸ“‚ Loading model from: {h5_path}")
        model = keras.models.load_model(h5_path)
        
        print(f"âœ… Model loaded successfully")
        print(f"ğŸ“Š Input shape: {model.input_shape}")
        print(f"ğŸ“Š Output shape: {model.output_shape}")
        
        # Save as SavedModel
        print(f"\nğŸ’¾ Saving as SavedModel to: {saved_model_path}")
        Path(saved_model_path).mkdir(parents=True, exist_ok=True)
        
        # Use TensorFlow's save API for Keras 3
        tf.saved_model.save(model, saved_model_path)
        
        print(f"âœ… SavedModel created successfully!")
        
        # Verify saved model
        if os.path.exists(os.path.join(saved_model_path, 'saved_model.pb')):
            print(f"âœ… saved_model.pb exists")
        
        if os.path.exists(os.path.join(saved_model_path, 'variables')):
            print(f"âœ… variables directory exists")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False

def convert_to_tfjs():
    """Convert SavedModel to TensorFlow.js format"""
    print("\nğŸ”„ Converting SavedModel to TensorFlow.js...")
    print("=" * 60)
    
    saved_model_path = "exports/saved_model"
    tfjs_path = "exports/tfjs_model"
    
    if not os.path.exists(saved_model_path):
        print(f"âŒ SavedModel not found: {saved_model_path}")
        return False
    
    try:
        import tensorflowjs as tfjs
        
        print(f"ğŸ“‚ Input: {saved_model_path}")
        print(f"ğŸ“‚ Output: {tfjs_path}")
        
        # Convert using tensorflowjs
        tfjs.converters.convert_tf_saved_model(
            saved_model_path,
            tfjs_path
        )
        
        print(f"\nâœ… TensorFlow.js model created successfully!")
        
        # Check files
        model_json = os.path.join(tfjs_path, 'model.json')
        if os.path.exists(model_json):
            print(f"âœ… model.json created")
            
            # Count weight files
            weight_files = list(Path(tfjs_path).glob('*.bin'))
            print(f"âœ… {len(weight_files)} weight file(s) created")
            
            # Get total size
            total_size = sum(f.stat().st_size for f in Path(tfjs_path).iterdir() if f.is_file())
            print(f"ğŸ“¦ Total size: {total_size / (1024*1024):.2f} MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_model_info():
    """Create model configuration file"""
    import json
    
    try:
        tfjs_path = "exports/tfjs_model"
        
        model_info = {
            "modelType": "hybrid_cnn_mobilenetv2",
            "inputShape": [224, 224, 3],
            "outputShape": [7],
            "classes": [
                "bacterial_wilt",
                "healthy",
                "leaf_spot",
                "rhizome_rot",
                "root_knot_nematode",
                "soft_rot",
                "yellow_disease"
            ],
            "preprocessing": {
                "rescale": "1/255",
                "resize": [224, 224],
                "normalize": True
            },
            "metadata": {
                "framework": "tensorflow",
                "version": "1.0.0",
                "created": "2025-10-28",
                "accuracy": "92.86%"
            }
        }
        
        info_path = os.path.join(tfjs_path, 'model_info.json')
        with open(info_path, 'w') as f:
            json.dump(model_info, f, indent=2)
        
        print(f"\nâœ… Model info saved: {info_path}")
        return True
        
    except Exception as e:
        print(f"âš ï¸ Warning: Could not create model info: {e}")
        return False

def main():
    """Main function"""
    print("ğŸ¤– Model Export Pipeline")
    print("=" * 60)
    
    # Step 1: Convert to SavedModel
    if not convert_h5_to_saved_model():
        print("\nâŒ Failed to convert to SavedModel")
        return False
    
    # Step 2: Convert to TensorFlow.js
    if not convert_to_tfjs():
        print("\nâŒ Failed to convert to TensorFlow.js")
        return False
    
    # Step 3: Create model info
    create_model_info()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ Model Export Complete!")
    print("=" * 60)
    print("\nğŸ“ Exported model: exports/tfjs_model/")
    print("\nğŸ“‹ Files created:")
    print("  - model.json (model architecture)")
    print("  - *.bin files (model weights)")
    print("  - model_info.json (model metadata)")
    print("\nğŸš€ Next Steps:")
    print("1. Copy exports/tfjs_model/ to your mobile app's assets folder")
    print("2. Load the model using TensorFlow.js in your Ionic app")
    print("3. Test predictions with sample images")
    
    return True

if __name__ == "__main__":
    main()

